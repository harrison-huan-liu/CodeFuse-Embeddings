{
  "model_path": "models/bert_multilingual",
  "experiment_id": "bert_multilingual+lr.2e-5+bs.32+context.512+3epochs",
  "train_data_path": "training_data/data_tokenized_bert",
  "output_dir": "output",
  "tb_dir": "output/tb",
  "cache_dir": "cache",
  "train_batch_size": 32,
  "checkpointing_steps": 5000,
  "validation_steps": 5000,
  "max_seq_length": 512,
  "learning_rate": 2e-5,
  "min_lr": 1e-7,
  "weight_decay": 0.01,
  "warmup_steps": 500,
  "train_epochs": 3,
  "log_interval": 100,
  "num_hard_neg": 7
}